import { AgentChatResponse } from '../types';

// Helper function to call our secure backend proxy
const callAIProxy = async (payload: any) => {
    try {
        const response = await fetch('/api/ai-proxy', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
            },
            body: JSON.stringify(payload)
        });

        if (!response.ok) {
            const errorData = await response.json().catch(() => ({}));
            throw new Error(errorData.error || `Server Error: ${response.status}`);
        }

        return await response.json();
    } catch (error) {
        console.error("AI Service Error:", error);
        throw error;
    }
};

const getGeminiModelName = (uiModel: string) => {
    const lowerModel = (uiModel || '').toLowerCase();
    if (lowerModel.includes('gpt-4') || lowerModel.includes('gemini-pro') || lowerModel.includes('sonnet')) {
        return 'gemini-3-pro-preview';
    } 
    return 'gemini-3-flash-preview';
};

export const generateDashboardInsight = async (metricsSummary: string): Promise<string> => {
  try {
    const result = await callAIProxy({
        model: 'gemini-3-flash-preview',
        contents: [{ role: 'user', parts: [{ text: metricsSummary }] }],
        config: {
            systemInstruction: 'Voc√™ √© um analista de dados SaaS experiente. Analise o contexto fornecido e gere UM √öNICO insight curto (m√°ximo 1 frase) e acion√°vel. Foque em tend√™ncias, riscos ou oportunidades. Use emojis.',
            temperature: 0.7
        }
    });

    return result.text || "Sem insights dispon√≠veis.";

  } catch (error) {
    console.warn("AI Insight Error:", error);
    return "‚ö†Ô∏è IA indispon√≠vel. Verifique conex√£o.";
  }
};

export const analyzeJourney = async (
    userName: string,
    daysSinceJoined: number,
    currentStage: string,
    daysStagnant: number,
    completedSteps: string[]
): Promise<string> => {
    try {
        const prompt = `
            Analise a jornada do cliente SaaS "${userName}" para identificar gargalos ou sucessos.
            
            DADOS:
            - Tempo de casa: ${daysSinceJoined} dias.
            - Est√°gio Atual (Travado em): ${currentStage}.
            - Dias sem avan√ßar (Estagna√ß√£o): ${daysStagnant} dias.
            - Etapas Feitas: ${completedSteps.join(', ')}.

            REGRAS OBRIGAT√ìRIAS:
            1. ESTAGNA√á√ÉO CR√çTICA: Se dias estagnado > 15, comece com "üö® ALERTA DE ESTAGNA√á√ÉO:". Sugira interven√ß√£o manual (liga√ß√£o/reuni√£o).
            2. PROVA SOCIAL: Se completou "Valor Gerado" ou jornada completa, comece com "üíé OPORTUNIDADE DE CASE:". Sugira pedir depoimento.
            3. NORMAL: Se tudo ok, d√™ uma dica t√°tica para o pr√≥ximo passo.

            Seja curto (m√°ximo 2 frases). Direto ao ponto.
        `;
        
        const result = await callAIProxy({
            model: 'gemini-3-flash-preview',
            contents: [{ role: 'user', parts: [{ text: prompt }] }],
            config: {
                temperature: 0.4 
            }
        });

        return result.text || "An√°lise indispon√≠vel no momento.";

    } catch (error) {
        console.error("AI Journey Analysis Error:", error);
        return "N√£o foi poss√≠vel gerar o diagn√≥stico autom√°tico.";
    }
};

export const generateAgentChat = async (
  uiModelName: string,
  systemPrompt: string,
  temperature: number,
  history: { role: 'user' | 'assistant'; content: string }[],
  newMessage: string
): Promise<AgentChatResponse> => {
  
  const modelName = getGeminiModelName(uiModelName);

  const contents = history.map((msg) => ({
    role: msg.role === 'assistant' ? 'model' : 'user',
    parts: [{ text: msg.content }]
  }));

  contents.push({
      role: 'user',
      parts: [{ text: newMessage }]
  });

  try {
      const result = await callAIProxy({
        model: modelName,
        contents: contents,
        config: {
          systemInstruction: systemPrompt,
          temperature: temperature || 0.7,
        }
      });

      return {
        text: result.text || "O modelo n√£o retornou texto.",
        usage: result.usage || { totalTokens: 0, promptTokens: 0, responseTokens: 0 }
      };
  } catch (error: any) {
      console.error("Agent Execution Error Details:", error);
      throw new Error(`Erro na IA: ${error.message || 'Falha de comunica√ß√£o com o servidor'}`);
  }
};